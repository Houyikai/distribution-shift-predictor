{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from neuralforecast.models.patchtst import PatchTST\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import pandas as pd\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models.mixmodel_rescale_deco import MIXModel\n",
    "from neuralforecast.losses.pytorch import MAE, MSE\n",
    "from neuralforecast.losses.numpy import mae, mse\n",
    "# from datasetsforecast.long_horizon import LongHorizon, LongHorizonInfo\n",
    "from datasetsforecast.long_horizon2 import LongHorizon2, LongHorizon2Info\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
    "epochs = 300\n",
    "def timedeter(modelname,horizon,dataset):\n",
    "  if modelname == 'MIXModel':\n",
    "    model = MIXModel(\n",
    "        h = horizon,\n",
    "        input_size = 512,\n",
    "        decomp_kernel_size = 25, \n",
    "        transformer_input_size = 192,\n",
    "        n_blocks = [1, 1, 1],\n",
    "        mlp_units = 3 * [[256, 256]],\n",
    "        n_pool_kernel_size = [16, 8, 1],\n",
    "        n_freq_downsample = [16, 8, 1],\n",
    "        pooling_mode = \"MaxPool1d\",\n",
    "        interpolation_mode = \"linear\",\n",
    "        dropout_prob_theta=0.2,\n",
    "        mlp_activation = \"ReLU\",\n",
    "        \n",
    "        encoder_layers = 3,\n",
    "        n_heads = 4,\n",
    "        hidden_size = 64,\n",
    "        linear_hidden_size = 128,\n",
    "        dropout = 0.2,\n",
    "        fc_dropout = 0.2,\n",
    "        head_dropout = 0.0,\n",
    "        attn_dropout = 0.0,\n",
    "        patch_len = 16,\n",
    "        stride = 8,\n",
    "        revin = True,\n",
    "        revin_affine = False,\n",
    "        revin_subtract_last = True,\n",
    "        activation = \"gelu\",\n",
    "        res_attention = True,\n",
    "        batch_normalization = False,\n",
    "        learn_pos_embed = True,\n",
    "        loss=MAE(),\n",
    "        valid_loss=MAE(),\n",
    "        max_steps = epochs,\n",
    "        learning_rate = 1e-4,\n",
    "        num_lr_decays = -1,\n",
    "        early_stop_patience_steps = 3,\n",
    "        val_check_steps = 20,\n",
    "        batch_size = 128,\n",
    "        valid_batch_size = None,\n",
    "        windows_batch_size = 1024, \n",
    "        inference_windows_batch_size = 1024,\n",
    "        step_size = 2, \n",
    "        scaler_type = \"identity\",\n",
    "        random_seed = 2023,\n",
    "        num_workers_loader = 0, # 取决于 cpu 数量\n",
    "        stat_exog_list=None,\n",
    "        hist_exog_list=None,\n",
    "        futr_exog_list=None,\n",
    "        exclude_insample_y=False,\n",
    "        drop_last_loader = False,\n",
    ")\n",
    "  elif modelname == 'PatchTST':\n",
    "    model = PatchTST(\n",
    "        h = horizon,\n",
    "        input_size = 336,\n",
    "        \n",
    "        encoder_layers = 3,\n",
    "        n_heads = 8,\n",
    "        hidden_size = 64,\n",
    "        linear_hidden_size = 256,\n",
    "        dropout = 0.2,\n",
    "        fc_dropout = 0.2,\n",
    "        head_dropout = 0.0,\n",
    "        attn_dropout = 0.0,\n",
    "        patch_len = 16,\n",
    "        stride = 8,\n",
    "        revin = True,\n",
    "        revin_affine = False,\n",
    "        revin_subtract_last = True,\n",
    "        activation = \"gelu\",\n",
    "        res_attention = True,\n",
    "        batch_normalization = False,\n",
    "        learn_pos_embed = True,\n",
    "        loss=MAE(),\n",
    "        valid_loss=MAE(),\n",
    "        max_steps = epochs,\n",
    "        learning_rate = 1e-3,\n",
    "        num_lr_decays = -1,\n",
    "        early_stop_patience_steps = 3,\n",
    "        val_check_steps = 10,\n",
    "        batch_size = 32,\n",
    "        valid_batch_size = None,\n",
    "        windows_batch_size = 1024, \n",
    "        inference_windows_batch_size = 1024,\n",
    "        step_size = 2, \n",
    "        scaler_type = \"standard\",\n",
    "        random_seed = 2023,\n",
    "        num_workers_loader = 0, # 取决于 cpu 数量\n",
    "        stat_exog_list=None,\n",
    "        hist_exog_list=None,\n",
    "        futr_exog_list=None,\n",
    "        exclude_insample_y=False,\n",
    "        drop_last_loader = False,\n",
    ")\n",
    "\n",
    "  Y_df = LongHorizon2.load(directory=\"./data/\", group=dataset)\n",
    "  Y_df[\"ds\"] = pd.to_datetime(Y_df[\"ds\"])\n",
    "  n_time = LongHorizon2Info[dataset].n_time\n",
    "  freq = LongHorizon2Info[dataset].freq\n",
    "  val_size = LongHorizon2Info[dataset].val_size\n",
    "  test_size = LongHorizon2Info[dataset].test_size\n",
    "  Y_df.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "  # fit & test model\n",
    "  nf = NeuralForecast(models=[model], freq=freq)\n",
    "  Y_hat_df = nf.cross_validation(df=Y_df, val_size=val_size, test_size=test_size,step_size=1, n_windows=None)\n",
    "  # calculate matrics\n",
    "  y_true = Y_hat_df.y.values\n",
    "  y_hat = Y_hat_df[modelname].values\n",
    "  n_series = len(Y_hat_df.unique_id.unique())\n",
    "  y_true = y_true.reshape(n_series, -1, horizon)\n",
    "  y_hat = y_hat.reshape(n_series, -1, horizon)\n",
    "  return mae(y_hat, y_true), mse(y_hat, y_true)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models = ['MIXModel', 'PatchTST']\n",
    "ETTh1_horizon = [24,24*7,24*7*2,24*30]\n",
    "ETTm1_horizon = [96,96*7,96*7*2]\n",
    "\n",
    "result = pd.DataFrame(columns=['model','dataset','horizon','mae','mse'])\n",
    "\n",
    "for model in models:\n",
    "  for horizon in ETTh1_horizon:\n",
    "    dataset = 'ETTh1'\n",
    "    _mae , _mse = timedeter(model,horizon,dataset)\n",
    "    result = result._append({'model':model,'dataset':dataset,'horizon':horizon,'mae':_mae,'mse':_mse},ignore_index=True)\n",
    "\n",
    "for model in models:\n",
    "  for horizon in ETTm1_horizon:\n",
    "    dataset = 'ETTm1'\n",
    "    _mae,_mse = timedeter(model,horizon,dataset)\n",
    "    result = result._append({'model':model,'dataset':dataset,'horizon':horizon,'mae':_mae,'mse':_mse},ignore_index=True)\n",
    "    \n",
    "result.to_csv('./data/time_determind.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>horizon</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIXModel</td>\n",
       "      <td>ETTh1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.333124</td>\n",
       "      <td>0.268059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MIXModel</td>\n",
       "      <td>ETTh1</td>\n",
       "      <td>168</td>\n",
       "      <td>0.394871</td>\n",
       "      <td>0.361756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIXModel</td>\n",
       "      <td>ETTh1</td>\n",
       "      <td>336</td>\n",
       "      <td>0.414464</td>\n",
       "      <td>0.397811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MIXModel</td>\n",
       "      <td>ETTh1</td>\n",
       "      <td>720</td>\n",
       "      <td>0.429437</td>\n",
       "      <td>0.386717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>ETTh1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.343953</td>\n",
       "      <td>0.277722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>ETTh1</td>\n",
       "      <td>168</td>\n",
       "      <td>0.391764</td>\n",
       "      <td>0.353621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>ETTh1</td>\n",
       "      <td>336</td>\n",
       "      <td>0.420193</td>\n",
       "      <td>0.395108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>ETTh1</td>\n",
       "      <td>720</td>\n",
       "      <td>0.457165</td>\n",
       "      <td>0.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MIXModel</td>\n",
       "      <td>ETTm1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.318104</td>\n",
       "      <td>0.253238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MIXModel</td>\n",
       "      <td>ETTm1</td>\n",
       "      <td>672</td>\n",
       "      <td>0.390404</td>\n",
       "      <td>0.363776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MIXModel</td>\n",
       "      <td>ETTm1</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.414419</td>\n",
       "      <td>0.404338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>ETTm1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.320028</td>\n",
       "      <td>0.253026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>ETTm1</td>\n",
       "      <td>672</td>\n",
       "      <td>0.416704</td>\n",
       "      <td>0.412215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>ETTm1</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.419404</td>\n",
       "      <td>0.420220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model dataset horizon       mae       mse\n",
       "0   MIXModel   ETTh1      24  0.333124  0.268059\n",
       "1   MIXModel   ETTh1     168  0.394871  0.361756\n",
       "2   MIXModel   ETTh1     336  0.414464  0.397811\n",
       "3   MIXModel   ETTh1     720  0.429437  0.386717\n",
       "4   PatchTST   ETTh1      24  0.343953  0.277722\n",
       "5   PatchTST   ETTh1     168  0.391764  0.353621\n",
       "6   PatchTST   ETTh1     336  0.420193  0.395108\n",
       "7   PatchTST   ETTh1     720  0.457165  0.429300\n",
       "8   MIXModel   ETTm1      96  0.318104  0.253238\n",
       "9   MIXModel   ETTm1     672  0.390404  0.363776\n",
       "10  MIXModel   ETTm1    1344  0.414419  0.404338\n",
       "11  PatchTST   ETTm1      96  0.320028  0.253026\n",
       "12  PatchTST   ETTm1     672  0.416704  0.412215\n",
       "13  PatchTST   ETTm1    1344  0.419404  0.420220"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hencoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
