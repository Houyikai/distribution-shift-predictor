{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.patchtst"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PatchTST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PatchTST model is an efficient Transformer-based model for multivariate time series forecasting.\n",
    "\n",
    "It is based on two key components:\n",
    "- segmentation of time series into windows (patches) which are served as input tokens to Transformer\n",
    "- channel-independence. where each channel contains a single univariate time series."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**<br>\n",
    "- [Nie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). \"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers\"](https://arxiv.org/pdf/2211.14730.pdf)<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1. PatchTST.](imgs_models/patchtst.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import Optional #, Any, Tuple\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(sys.path[0]))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from neuralforecast.common._base_windows import BaseWindows\n",
    "\n",
    "from neuralforecast.losses.pytorch import MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# from fastcore.test import test_eq\n",
    "# from nbdev.showdoc import show_doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Backbone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Transpose(nn.Module):\n",
    "    def __init__(self, *dims, contiguous=False): \n",
    "        super().__init__()\n",
    "        self.dims, self.contiguous = dims, contiguous\n",
    "    def forward(self, x):\n",
    "        if self.contiguous: return x.transpose(*self.dims).contiguous()\n",
    "        else: return x.transpose(*self.dims)\n",
    "\n",
    "def get_activation_fn(activation):\n",
    "    if callable(activation): return activation()\n",
    "    elif activation.lower() == \"relu\": return nn.ReLU()\n",
    "    elif activation.lower() == \"gelu\": return nn.GELU()\n",
    "    raise ValueError(f'{activation} is not available. You can use \"relu\", \"gelu\", or a callable') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def PositionalEncoding(q_len, hidden_size, normalize=True):\n",
    "    pe = torch.zeros(q_len, hidden_size)\n",
    "    position = torch.arange(0, q_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, hidden_size, 2) * -(math.log(10000.0) / hidden_size))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    if normalize:\n",
    "        pe = pe - pe.mean()\n",
    "        pe = pe / (pe.std() * 10)\n",
    "    return pe\n",
    "\n",
    "SinCosPosEncoding = PositionalEncoding\n",
    "\n",
    "def Coord2dPosEncoding(q_len, hidden_size, exponential=False, normalize=True, eps=1e-3):\n",
    "    x = .5 if exponential else 1\n",
    "    i = 0\n",
    "    for i in range(100):\n",
    "        cpe = 2 * (torch.linspace(0, 1, q_len).reshape(-1, 1) ** x) * (torch.linspace(0, 1, hidden_size).reshape(1, -1) ** x) - 1\n",
    "        if abs(cpe.mean()) <= eps: break\n",
    "        elif cpe.mean() > eps: x += .001\n",
    "        else: x -= .001\n",
    "        i += 1\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "def Coord1dPosEncoding(q_len, exponential=False, normalize=True):\n",
    "    cpe = (2 * (torch.linspace(0, 1, q_len).reshape(-1, 1)**(.5 if exponential else 1)) - 1)\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "def positional_encoding(pe, learn_pe, q_len, hidden_size):\n",
    "    # Positional encoding\n",
    "    if pe == None:\n",
    "        W_pos = torch.empty((q_len, hidden_size)) # pe = None and learn_pe = False can be used to measure impact of pe\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "        learn_pe = False\n",
    "    elif pe == 'zero':\n",
    "        W_pos = torch.empty((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'zeros':\n",
    "        W_pos = torch.empty((q_len, hidden_size))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'normal' or pe == 'gauss':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)\n",
    "    elif pe == 'uniform':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, a=0.0, b=0.1)\n",
    "    elif pe == 'lin1d': W_pos = Coord1dPosEncoding(q_len, exponential=False, normalize=True)\n",
    "    elif pe == 'exp1d': W_pos = Coord1dPosEncoding(q_len, exponential=True, normalize=True)\n",
    "    elif pe == 'lin2d': W_pos = Coord2dPosEncoding(q_len, hidden_size, exponential=False, normalize=True)\n",
    "    elif pe == 'exp2d': W_pos = Coord2dPosEncoding(q_len, hidden_size, exponential=True, normalize=True)\n",
    "    elif pe == 'sincos': W_pos = PositionalEncoding(q_len, hidden_size, normalize=True)\n",
    "    else: raise ValueError(f\"{pe} is not a valid pe (positional encoder. Available types: 'gauss'=='normal', \\\n",
    "        'zeros', 'zero', uniform', 'lin1d', 'exp1d', 'lin2d', 'exp2d', 'sincos', None.)\")\n",
    "    return nn.Parameter(W_pos, requires_grad=learn_pe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RevIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RevIN(nn.Module):\n",
    "    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
    "        \"\"\"\n",
    "        :param num_features: the number of features or channels\n",
    "        :param eps: a value added for numerical stability\n",
    "        :param affine: if True, RevIN has learnable affine parameters\n",
    "        \"\"\"\n",
    "        super(RevIN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "        if self.affine:\n",
    "            self._init_params()\n",
    "\n",
    "    def forward(self, x, mode:str):\n",
    "        if mode == 'norm':\n",
    "            self._get_statistics(x)\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x)\n",
    "        else: raise NotImplementedError\n",
    "        return x\n",
    "\n",
    "    def _init_params(self):\n",
    "        # initialize RevIN params: (C,)\n",
    "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
    "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        dim2reduce = tuple(range(1, x.ndim-1))\n",
    "        if self.subtract_last:\n",
    "            self.last = x[:,-1,:].unsqueeze(1)\n",
    "        else:\n",
    "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
    "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        if self.subtract_last:\n",
    "            x = x - self.last\n",
    "        else:\n",
    "            x = x - self.mean\n",
    "        x = x / self.stdev\n",
    "        if self.affine:\n",
    "            x = x * self.affine_weight\n",
    "            x = x + self.affine_bias\n",
    "        return x\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = x - self.affine_bias\n",
    "            x = x / (self.affine_weight + self.eps*self.eps)\n",
    "        x = x * self.stdev\n",
    "        if self.subtract_last:\n",
    "            x = x + self.last\n",
    "        else:\n",
    "            x = x + self.mean\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PatchTST_backbone(nn.Module):\n",
    "    def __init__(self, c_in:int, c_out:int, input_size:int, h:int, patch_len:int, stride:int, max_seq_len:Optional[int]=1024, \n",
    "                 n_layers:int=3, hidden_size=128, n_heads=16, d_k:Optional[int]=None, d_v:Optional[int]=None,\n",
    "                 linear_hidden_size:int=256, norm:str='BatchNorm', attn_dropout:float=0., dropout:float=0., act:str=\"gelu\", key_padding_mask:str='auto',\n",
    "                 padding_var:Optional[int]=None, attn_mask:Optional[torch.Tensor]=None, res_attention:bool=True, pre_norm:bool=False, store_attn:bool=False,\n",
    "                 pe:str='zeros', learn_pe:bool=True, fc_dropout:float=0., head_dropout = 0, padding_patch = None,\n",
    "                 pretrain_head:bool=False, head_type = 'flatten', individual = False, revin = True, affine = True, subtract_last = False):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        # RevIn\n",
    "        self.revin = revin\n",
    "        if self.revin: self.revin_layer = RevIN(c_in, affine=affine, subtract_last=subtract_last)\n",
    "\n",
    "        # Patching\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch = padding_patch\n",
    "        patch_num = int((input_size - patch_len)/stride + 1)\n",
    "        if padding_patch == 'end': # can be modified to general case\n",
    "            self.padding_patch_layer = nn.ReplicationPad1d((0, stride)) \n",
    "            patch_num += 1\n",
    "\n",
    "        # Backbone \n",
    "        self.backbone = TSTiEncoder(c_in, patch_num=patch_num, patch_len=patch_len, max_seq_len=max_seq_len,\n",
    "                                n_layers=n_layers, hidden_size=hidden_size, n_heads=n_heads, d_k=d_k, d_v=d_v, linear_hidden_size=linear_hidden_size,\n",
    "                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n",
    "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n",
    "                                pe=pe, learn_pe=learn_pe)\n",
    "\n",
    "        # Head\n",
    "        self.head_nf = hidden_size * patch_num\n",
    "        self.n_vars = c_in\n",
    "        self.c_out = c_out\n",
    "        self.pretrain_head = pretrain_head\n",
    "        self.head_type = head_type\n",
    "        self.individual = individual\n",
    "\n",
    "        if self.pretrain_head: \n",
    "            self.head = self.create_pretrain_head(self.head_nf, c_in, fc_dropout) # custom head passed as a partial func with all its kwargs\n",
    "        elif head_type == 'flatten': \n",
    "            self.head = Flatten_Head(self.individual, self.n_vars, self.head_nf, h, c_out, head_dropout=head_dropout)\n",
    "\n",
    "    def forward(self, z):                                                                   # z: [bs x nvars x seq_len]\n",
    "        # norm\n",
    "        if self.revin: \n",
    "            z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'norm')\n",
    "            z = z.permute(0,2,1)\n",
    "\n",
    "        # do patching\n",
    "        if self.padding_patch == 'end':\n",
    "            z = self.padding_patch_layer(z)\n",
    "        z = z.unfold(dimension=-1, size=self.patch_len, step=self.stride)                   # z: [bs x nvars x patch_num x patch_len]\n",
    "        z = z.permute(0,1,3,2)                                                              # z: [bs x nvars x patch_len x patch_num]\n",
    "\n",
    "        # model\n",
    "        z = self.backbone(z)                                                                # z: [bs x nvars x hidden_size x patch_num]\n",
    "        z = self.head(z)                                                                    # z: [bs x nvars x h] \n",
    "\n",
    "        # denorm\n",
    "        if self.revin:\n",
    "            z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'denorm')\n",
    "            z = z.permute(0,2,1)\n",
    "            \n",
    "        return z\n",
    "    \n",
    "    def create_pretrain_head(self, head_nf, vars, dropout):\n",
    "        return nn.Sequential(nn.Dropout(dropout),\n",
    "                    nn.Conv1d(head_nf, vars, 1)\n",
    "                    )\n",
    "\n",
    "\n",
    "class Flatten_Head(nn.Module):\n",
    "    def __init__(self, individual, n_vars, nf, h, c_out, head_dropout=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.individual = individual\n",
    "        self.n_vars = n_vars\n",
    "        self.c_out = c_out\n",
    "        \n",
    "        if self.individual:\n",
    "            self.linears = nn.ModuleList()\n",
    "            self.dropouts = nn.ModuleList()\n",
    "            self.flattens = nn.ModuleList()\n",
    "            for i in range(self.n_vars):\n",
    "                self.flattens.append(nn.Flatten(start_dim=-2))\n",
    "                self.linears.append(nn.Linear(nf, h*c_out))\n",
    "                self.dropouts.append(nn.Dropout(head_dropout))\n",
    "        else:\n",
    "            self.flatten = nn.Flatten(start_dim=-2)\n",
    "            self.linear = nn.Linear(nf, h*c_out)\n",
    "            self.dropout = nn.Dropout(head_dropout)\n",
    "            \n",
    "    def forward(self, x):                                 # x: [bs x nvars x hidden_size x patch_num]\n",
    "        if self.individual:\n",
    "            x_out = []\n",
    "            for i in range(self.n_vars):\n",
    "                z = self.flattens[i](x[:,i,:,:])          # z: [bs x hidden_size * patch_num]\n",
    "                z = self.linears[i](z)                    # z: [bs x h]\n",
    "                z = self.dropouts[i](z)\n",
    "                x_out.append(z)\n",
    "            x = torch.stack(x_out, dim=1)                 # x: [bs x nvars x h]\n",
    "        else:\n",
    "            x = self.flatten(x)\n",
    "            x = self.linear(x)\n",
    "            x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TSTiEncoder(nn.Module):  #i means channel-independent\n",
    "    def __init__(self, c_in, patch_num, patch_len, max_seq_len=1024,\n",
    "                 n_layers=3, hidden_size=128, n_heads=16, d_k=None, d_v=None,\n",
    "                 linear_hidden_size=256, norm='BatchNorm', attn_dropout=0., dropout=0., act=\"gelu\", store_attn=False,\n",
    "                 key_padding_mask='auto', padding_var=None, attn_mask=None, res_attention=True, pre_norm=False,\n",
    "                 pe='zeros', learn_pe=True):\n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.patch_num = patch_num\n",
    "        self.patch_len = patch_len\n",
    "        \n",
    "        # Input encoding\n",
    "        q_len = patch_num\n",
    "        self.W_P = nn.Linear(patch_len, hidden_size)        # Eq 1: projection of feature vectors onto a d-dim vector space\n",
    "        self.seq_len = q_len\n",
    "\n",
    "        # Positional encoding\n",
    "        self.W_pos = positional_encoding(pe, learn_pe, q_len, hidden_size)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = TSTEncoder(q_len, hidden_size, n_heads, d_k=d_k, d_v=d_v, linear_hidden_size=linear_hidden_size, norm=norm, attn_dropout=attn_dropout, dropout=dropout,\n",
    "                                   pre_norm=pre_norm, activation=act, res_attention=res_attention, n_layers=n_layers, store_attn=store_attn)\n",
    "        \n",
    "    def forward(self, x) -> torch.Tensor:                                        # x: [bs x nvars x patch_len x patch_num]\n",
    "        \n",
    "        n_vars = x.shape[1]\n",
    "        # Input encoding\n",
    "        x = x.permute(0,1,3,2)                                                   # x: [bs x nvars x patch_num x patch_len]\n",
    "        x = self.W_P(x)                                                          # x: [bs x nvars x patch_num x hidden_size]\n",
    "\n",
    "        u = torch.reshape(x, (x.shape[0]*x.shape[1],x.shape[2],x.shape[3]))      # u: [bs * nvars x patch_num x hidden_size]\n",
    "        u = self.dropout(u + self.W_pos)                                         # u: [bs * nvars x patch_num x hidden_size]\n",
    "\n",
    "        # Encoder\n",
    "        z = self.encoder(u)                                                      # z: [bs * nvars x patch_num x hidden_size]\n",
    "        z = torch.reshape(z, (-1,n_vars,z.shape[-2],z.shape[-1]))                # z: [bs x nvars x patch_num x hidden_size]\n",
    "        z = z.permute(0,1,3,2)                                                   # z: [bs x nvars x hidden_size x patch_num]\n",
    "        \n",
    "        return z    \n",
    "            \n",
    "\n",
    "class TSTEncoder(nn.Module):\n",
    "    def __init__(self, q_len, hidden_size, n_heads, d_k=None, d_v=None, linear_hidden_size=None, \n",
    "                        norm='BatchNorm', attn_dropout=0., dropout=0., activation='gelu',\n",
    "                        res_attention=False, n_layers=1, pre_norm=False, store_attn=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([TSTEncoderLayer(q_len, hidden_size, n_heads=n_heads, d_k=d_k, d_v=d_v, linear_hidden_size=linear_hidden_size, norm=norm,\n",
    "                                                      attn_dropout=attn_dropout, dropout=dropout,\n",
    "                                                      activation=activation, res_attention=res_attention,\n",
    "                                                      pre_norm=pre_norm, store_attn=store_attn) for i in range(n_layers)])\n",
    "        self.res_attention = res_attention\n",
    "\n",
    "    def forward(self, src:torch.Tensor, key_padding_mask:Optional[torch.Tensor]=None, attn_mask:Optional[torch.Tensor]=None):\n",
    "        output = src\n",
    "        scores = None\n",
    "        if self.res_attention:\n",
    "            for mod in self.layers: output, scores = mod(output, prev=scores, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "            return output\n",
    "        else:\n",
    "            for mod in self.layers: output = mod(output, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "            return output\n",
    "\n",
    "\n",
    "class TSTEncoderLayer(nn.Module):\n",
    "    def __init__(self, q_len, hidden_size, n_heads, d_k=None, d_v=None, linear_hidden_size=256, store_attn=False,\n",
    "                 norm='BatchNorm', attn_dropout=0, dropout=0., bias=True, activation=\"gelu\", res_attention=False, pre_norm=False):\n",
    "        super().__init__()\n",
    "        assert not hidden_size%n_heads, f\"hidden_size ({hidden_size}) must be divisible by n_heads ({n_heads})\"\n",
    "        d_k = hidden_size // n_heads if d_k is None else d_k\n",
    "        d_v = hidden_size // n_heads if d_v is None else d_v\n",
    "\n",
    "        # Multi-Head attention\n",
    "        self.res_attention = res_attention\n",
    "        self.self_attn = _MultiheadAttention(hidden_size, n_heads, d_k, d_v, attn_dropout=attn_dropout,\n",
    "                                             proj_dropout=dropout, res_attention=res_attention)\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_attn = nn.Dropout(dropout)\n",
    "        if \"batch\" in norm.lower():\n",
    "            self.norm_attn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(hidden_size), Transpose(1,2))\n",
    "        else:\n",
    "            self.norm_attn = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        # Position-wise Feed-Forward\n",
    "        self.ff = nn.Sequential(nn.Linear(hidden_size, linear_hidden_size, bias=bias),\n",
    "                                get_activation_fn(activation),\n",
    "                                nn.Dropout(dropout),\n",
    "                                nn.Linear(linear_hidden_size, hidden_size, bias=bias))\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_ffn = nn.Dropout(dropout)\n",
    "        if \"batch\" in norm.lower():\n",
    "            self.norm_ffn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(hidden_size), Transpose(1,2))\n",
    "        else:\n",
    "            self.norm_ffn = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.pre_norm = pre_norm\n",
    "        self.store_attn = store_attn\n",
    "\n",
    "    def forward(self, src:torch.Tensor, prev:Optional[torch.Tensor]=None,\n",
    "                key_padding_mask:Optional[torch.Tensor]=None,\n",
    "                attn_mask:Optional[torch.Tensor]=None): # -> Tuple[torch.Tensor, Any]:\n",
    "\n",
    "        # Multi-Head attention sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "        ## Multi-Head attention\n",
    "        if self.res_attention:\n",
    "            src2, attn, scores = self.self_attn(src, src, src, prev,\n",
    "                                                key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            src2, attn = self.self_attn(src, src, src, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        if self.store_attn:\n",
    "            self.attn = attn\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "\n",
    "        # Feed-forward sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "        ## Position-wise Feed-Forward\n",
    "        src2 = self.ff(src)\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "\n",
    "        if self.res_attention:\n",
    "            return src, scores\n",
    "        else:\n",
    "            return src\n",
    "\n",
    "\n",
    "class _MultiheadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, n_heads, d_k=None, d_v=None,\n",
    "                 res_attention=False, attn_dropout=0., proj_dropout=0., qkv_bias=True, lsa=False):\n",
    "        \"\"\"\n",
    "        Multi Head Attention Layer\n",
    "        Input shape:\n",
    "            Q:       [batch_size (bs) x max_q_len x hidden_size]\n",
    "            K, V:    [batch_size (bs) x q_len x hidden_size]\n",
    "            mask:    [q_len x q_len]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        d_k = hidden_size // n_heads if d_k is None else d_k\n",
    "        d_v = hidden_size // n_heads if d_v is None else d_v\n",
    "\n",
    "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(hidden_size, d_k * n_heads, bias=qkv_bias)\n",
    "        self.W_K = nn.Linear(hidden_size, d_k * n_heads, bias=qkv_bias)\n",
    "        self.W_V = nn.Linear(hidden_size, d_v * n_heads, bias=qkv_bias)\n",
    "\n",
    "        # Scaled Dot-Product Attention (multiple heads)\n",
    "        self.res_attention = res_attention\n",
    "        self.sdp_attn = _ScaledDotProductAttention(hidden_size, n_heads, attn_dropout=attn_dropout,\n",
    "                                                   res_attention=self.res_attention, lsa=lsa)\n",
    "\n",
    "        # Poject output\n",
    "        self.to_out = nn.Sequential(nn.Linear(n_heads * d_v, hidden_size), nn.Dropout(proj_dropout))\n",
    "\n",
    "    def forward(self, Q:torch.Tensor, K:Optional[torch.Tensor]=None, V:Optional[torch.Tensor]=None, prev:Optional[torch.Tensor]=None,\n",
    "                key_padding_mask:Optional[torch.Tensor]=None, attn_mask:Optional[torch.Tensor]=None):\n",
    "\n",
    "        bs = Q.size(0)\n",
    "        if K is None: K = Q\n",
    "        if V is None: V = Q\n",
    "\n",
    "        # Linear (+ split in multiple heads)\n",
    "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x max_q_len x d_k]\n",
    "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
    "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]\n",
    "\n",
    "        # Apply Scaled Dot-Product Attention (multiple heads)\n",
    "        if self.res_attention:\n",
    "            output, attn_weights, attn_scores = self.sdp_attn(q_s, k_s, v_s,\n",
    "                                                    prev=prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            output, attn_weights = self.sdp_attn(q_s, k_s, v_s, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        # output: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len], scores: [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # back to the original inputs dimensions\n",
    "        output = output.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # output: [bs x q_len x n_heads * d_v]\n",
    "        output = self.to_out(output)\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights\n",
    "\n",
    "\n",
    "class _ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Scaled Dot-Product Attention module (Attention is all you need by Vaswani et al., 2017) with optional residual attention from previous layer\n",
    "    (Realformer: Transformer likes residual attention by He et al, 2020) and locality self sttention (Vision Transformer for Small-Size Datasets\n",
    "    by Lee et al, 2021)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, n_heads, attn_dropout=0., res_attention=False, lsa=False):\n",
    "        super().__init__()\n",
    "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
    "        self.res_attention = res_attention\n",
    "        head_dim = hidden_size // n_heads\n",
    "        self.scale = nn.Parameter(torch.tensor(head_dim ** -0.5), requires_grad=lsa)\n",
    "        self.lsa = lsa\n",
    "\n",
    "    def forward(self, q:torch.Tensor, k:torch.Tensor, v:torch.Tensor,\n",
    "                prev:Optional[torch.Tensor]=None, key_padding_mask:Optional[torch.Tensor]=None,\n",
    "                attn_mask:Optional[torch.Tensor]=None):\n",
    "        '''\n",
    "        Input shape:\n",
    "            q               : [bs x n_heads x max_q_len x d_k]\n",
    "            k               : [bs x n_heads x d_k x seq_len]\n",
    "            v               : [bs x n_heads x seq_len x d_v]\n",
    "            prev            : [bs x n_heads x q_len x seq_len]\n",
    "            key_padding_mask: [bs x seq_len]\n",
    "            attn_mask       : [1 x seq_len x seq_len]\n",
    "        Output shape:\n",
    "            output:  [bs x n_heads x q_len x d_v]\n",
    "            attn   : [bs x n_heads x q_len x seq_len]\n",
    "            scores : [bs x n_heads x q_len x seq_len]\n",
    "        '''\n",
    "\n",
    "        # Scaled MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
    "        attn_scores = torch.matmul(q, k) * self.scale      # attn_scores : [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # Add pre-softmax attention scores from the previous layer (optional)\n",
    "        if prev is not None: attn_scores = attn_scores + prev\n",
    "\n",
    "        # Attention mask (optional)\n",
    "        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len\n",
    "            if attn_mask.dtype == torch.bool:\n",
    "                attn_scores.masked_fill_(attn_mask, -np.inf)\n",
    "            else:\n",
    "                attn_scores += attn_mask\n",
    "\n",
    "        # Key padding mask (optional)\n",
    "        if key_padding_mask is not None:                              # mask with shape [bs x q_len] (only when max_w_len == q_len)\n",
    "            attn_scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), -np.inf)\n",
    "\n",
    "        # normalize the attention weights\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)                 # attn_weights   : [bs x n_heads x max_q_len x q_len]\n",
    "        attn_weights = self.attn_dropout(attn_weights)\n",
    "\n",
    "        # compute the new values given the attention weights\n",
    "        output = torch.matmul(attn_weights, v)                        # output: [bs x n_heads x max_q_len x d_v]\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PatchTST(BaseWindows):\n",
    "    \"\"\" PatchTST\n",
    "\n",
    "    The PatchTST model is an efficient Transformer-based model for multivariate time series forecasting.\n",
    "\n",
    "    It is based on two key components:\n",
    "    - segmentation of time series into windows (patches) which are served as input tokens to Transformer\n",
    "    - channel-independence, where each channel contains a single univariate time series.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `h`: int, Forecast horizon. <br>\n",
    "    `input_size`: int, autorregresive inputs size, y=[1,2,3,4] input_size=2 -> y_[t-2:t]=[1,2].<br>\n",
    "    `stat_exog_list`: str list, static exogenous columns.<br>\n",
    "    `hist_exog_list`: str list, historic exogenous columns.<br>\n",
    "    `futr_exog_list`: str list, future exogenous columns.<br>\n",
    "    `exclude_insample_y`: bool=False, the model skips the autoregressive features y[t-input_size:t] if True.<br>\n",
    "    `encoder_layers`: int, number of layers for encoder.<br>\n",
    "    `n_heads`: int=16, number of multi-head's attention.<br>\n",
    "    `hidden_size`: int=128, units of embeddings and encoders.<br>\n",
    "    `linear_hidden_size`: int=256, units of linear layer.<br>\n",
    "    `dropout`: float=0.1, dropout rate for residual connection.<br>\n",
    "    `fc_dropout`: float=0.1, dropout rate for linear layer.<br>\n",
    "    `head_dropout`: float=0.1, dropout rate for Flatten head layer.<br>\n",
    "    `attn_dropout`: float=0.1, dropout rate for attention layer.<br>\n",
    "    `patch_len`: int=32, length of patch.<br>\n",
    "    `stride`: int=16, stride of patch.<br>\n",
    "    `revin`: bool=True, bool to use RevIn.<br>\n",
    "    `revin_affine`: bool=False, bool to use affine in RevIn.<br>\n",
    "    `revin_substract_last`: bool=False, bool to use substract last in RevIn.<br>\n",
    "    `activation`: str='ReLU', activation from ['gelu','relu'].<br>\n",
    "    `res_attention`: bool=False, bool to use residual attention.<br>\n",
    "    `batch_normalization`: bool=False, bool to use batch normalization.<br>\n",
    "    `learn_pos_embedding`: bool=True, bool to learn positional embedding.<br>\n",
    "    `loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
    "    `valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
    "    `max_steps`: int=1000, maximum number of training steps.<br>\n",
    "    `learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
    "    `num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
    "    `early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
    "    `val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
    "    `batch_size`: int=32, number of different series in each batch.<br>\n",
    "    `valid_batch_size`: int=None, number of different series in each validation and test batch, if None uses batch_size.<br>\n",
    "    `windows_batch_size`: int=1024, number of windows to sample in each training batch, default uses all.<br>\n",
    "    `inference_windows_batch_size`: int=1024, number of windows to sample in each inference batch.<br>\n",
    "    `step_size`: int=1, step size between each window of temporal data.<br>\n",
    "    `scaler_type`: str='identity', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
    "    `random_seed`: int, random_seed for pytorch initializer and numpy generators.<br>\n",
    "    `num_workers_loader`: int=os.cpu_count(), workers to be used by `TimeSeriesDataLoader`.<br>\n",
    "    `drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
    "    `alias`: str, optional,  Custom name of the model.<br>\n",
    "    `**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>    \n",
    "\n",
    "    **References:**<br>\n",
    "    -[Nie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). \"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers\"](https://arxiv.org/pdf/2211.14730.pdf)\n",
    "    \"\"\"\n",
    "    # Class attributes\n",
    "    SAMPLING_TYPE = 'windows'\n",
    "\n",
    "    def __init__(self,\n",
    "                 h,\n",
    "                 input_size,\n",
    "                 stat_exog_list = None,\n",
    "                 hist_exog_list = None,\n",
    "                 futr_exog_list = None,\n",
    "                 exclude_insample_y = False,\n",
    "                 encoder_layers: int = 3,\n",
    "                 n_heads: int = 16,\n",
    "                 hidden_size: int = 128,\n",
    "                 linear_hidden_size: int = 256,\n",
    "                 dropout: float = 0.2,\n",
    "                 fc_dropout: float = 0.2,\n",
    "                 head_dropout: float = 0.0,\n",
    "                 attn_dropout: float = 0.,\n",
    "                 patch_len: int = 16,\n",
    "                 stride: int = 8,\n",
    "                 revin: bool = True,\n",
    "                 revin_affine: bool = False,\n",
    "                 revin_subtract_last: bool = True,\n",
    "                 activation: str = \"gelu\",\n",
    "                 res_attention: bool = True, \n",
    "                 batch_normalization: bool = False,\n",
    "                 learn_pos_embed: bool = True,\n",
    "                 loss = MAE(),\n",
    "                 valid_loss = None,\n",
    "                 max_steps: int = 5000,\n",
    "                 learning_rate: float = 1e-4,\n",
    "                 num_lr_decays: int = -1,\n",
    "                 early_stop_patience_steps: int =-1,\n",
    "                 val_check_steps: int = 100,\n",
    "                 batch_size: int = 32,\n",
    "                 valid_batch_size: Optional[int] = None,\n",
    "                 windows_batch_size = 1024,\n",
    "                 inference_windows_batch_size: int = 1024,\n",
    "                 step_size: int = 1,\n",
    "                 scaler_type: str = 'identity',\n",
    "                 random_seed: int = 1,\n",
    "                 num_workers_loader: int = 0,\n",
    "                 drop_last_loader: bool = False,\n",
    "                 **trainer_kwargs):\n",
    "        super(PatchTST, self).__init__(h=h,\n",
    "                                       input_size=input_size,\n",
    "                                       hist_exog_list=hist_exog_list,\n",
    "                                       stat_exog_list=stat_exog_list,\n",
    "                                       futr_exog_list = futr_exog_list,\n",
    "                                       exclude_insample_y = exclude_insample_y,\n",
    "                                       loss=loss,\n",
    "                                       valid_loss=valid_loss,\n",
    "                                       max_steps=max_steps,\n",
    "                                       learning_rate=learning_rate,\n",
    "                                       num_lr_decays=num_lr_decays,\n",
    "                                       early_stop_patience_steps=early_stop_patience_steps,\n",
    "                                       val_check_steps=val_check_steps,\n",
    "                                       batch_size=batch_size,\n",
    "                                       valid_batch_size=valid_batch_size,\n",
    "                                       windows_batch_size=windows_batch_size,\n",
    "                                       inference_windows_batch_size=inference_windows_batch_size,\n",
    "                                       step_size=step_size,\n",
    "                                       scaler_type=scaler_type,\n",
    "                                       num_workers_loader=num_workers_loader,\n",
    "                                       drop_last_loader=drop_last_loader,\n",
    "                                       random_seed=random_seed,\n",
    "                                       **trainer_kwargs) \n",
    "        # Asserts\n",
    "        if stat_exog_list is not None:\n",
    "            raise Exception(\"PatchTST does not yet support static exogenous variables\")\n",
    "        if futr_exog_list is not None:\n",
    "            raise Exception(\"PatchTST does not yet support future exogenous variables\")\n",
    "        if hist_exog_list is not None:\n",
    "            raise Exception(\"PatchTST does not yet support historical exogenous variables\")\n",
    "        \n",
    "        c_out = self.loss.outputsize_multiplier\n",
    "\n",
    "        # Fixed hyperparameters\n",
    "        c_in = 1                  # Always univariate\n",
    "        padding_patch='end'       # Padding at the end\n",
    "        pretrain_head = False     # No pretrained head\n",
    "        norm = 'BatchNorm'        # Use BatchNorm (if batch_normalization is True)\n",
    "        pe = 'zeros'              # Initial zeros for positional encoding \n",
    "        d_k = None                # Key dimension\n",
    "        d_v = None                # Value dimension\n",
    "        store_attn = False        # Store attention weights\n",
    "        head_type = 'flatten'     # Head type\n",
    "        individual = False        # Separate heads for each time series\n",
    "        max_seq_len = 1024        # Not used\n",
    "        key_padding_mask = 'auto' # Not used\n",
    "        padding_var = None        # Not used\n",
    "        attn_mask = None          # Not used\n",
    "\n",
    "        self.model = PatchTST_backbone(c_in=c_in, c_out=c_out, input_size=input_size, h=h, patch_len=patch_len, stride=stride, \n",
    "                                max_seq_len=max_seq_len, n_layers=encoder_layers, hidden_size=hidden_size,\n",
    "                                n_heads=n_heads, d_k=d_k, d_v=d_v, linear_hidden_size=linear_hidden_size, norm=norm, attn_dropout=attn_dropout,\n",
    "                                dropout=dropout, act=activation, key_padding_mask=key_padding_mask, padding_var=padding_var, \n",
    "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=batch_normalization, store_attn=store_attn,\n",
    "                                pe=pe, learn_pe=learn_pos_embed, fc_dropout=fc_dropout, head_dropout=head_dropout, padding_patch = padding_patch,\n",
    "                                pretrain_head=pretrain_head, head_type=head_type, individual=individual, revin=revin, affine=revin_affine,\n",
    "                                subtract_last=revin_subtract_last)\n",
    "    \n",
    "    \n",
    "    def forward(self, windows_batch):  # x: [batch, input_size]\n",
    "\n",
    "        # Parse windows_batch\n",
    "        insample_y    = windows_batch['insample_y']\n",
    "        #insample_mask = windows_batch['insample_mask']\n",
    "        #hist_exog     = windows_batch['hist_exog']\n",
    "        #stat_exog     = windows_batch['stat_exog']\n",
    "        #futr_exog     = windows_batch['futr_exog']\n",
    "\n",
    "        # Add dimension for channel\n",
    "        x = insample_y.unsqueeze(-1) # [Ws,L,1]\n",
    "\n",
    "        x = x.permute(0,2,1)    # x: [Batch, 1, input_size]\n",
    "        x = self.model(x)\n",
    "        x = x.reshape(x.shape[0], self.h, -1) # x: [Batch, h, c_out]\n",
    "\n",
    "        # Domain map\n",
    "        forecast = self.loss.domain_map(x)\n",
    "        \n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(PatchTST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(PatchTST.fit, name='PatchTST.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(PatchTST.predict, name='PatchTST.predict')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "maximum size for tensor at dimension 2 is 132 but size is 812",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 37\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[39m=\u001b[39m PatchTST(h\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m\u001b[39m*\u001b[39m\u001b[39m7\u001b[39m,\n\u001b[0;32m     19\u001b[0m                  input_size\u001b[39m=\u001b[39m\u001b[39m104\u001b[39m\u001b[39m*\u001b[39m\u001b[39m7\u001b[39m,\n\u001b[0;32m     20\u001b[0m                  patch_len\u001b[39m=\u001b[39m\u001b[39m24\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m                  val_check_steps\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m,\n\u001b[0;32m     31\u001b[0m                  early_stop_patience_steps\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     33\u001b[0m nf \u001b[39m=\u001b[39m NeuralForecast(\n\u001b[0;32m     34\u001b[0m     models\u001b[39m=\u001b[39m[model],\n\u001b[0;32m     35\u001b[0m     freq\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mM\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     36\u001b[0m )\n\u001b[1;32m---> 37\u001b[0m nf\u001b[39m.\u001b[39mfit(df\u001b[39m=\u001b[39mY_train_df, static_df\u001b[39m=\u001b[39mAirPassengersStatic, val_size\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m)\n\u001b[0;32m     38\u001b[0m forecasts \u001b[39m=\u001b[39m nf\u001b[39m.\u001b[39mpredict(futr_df\u001b[39m=\u001b[39mY_test_df)\n",
      "File \u001b[1;32md:\\code\\project\\neuralforecast\\neuralforecast\\core.py:256\u001b[0m, in \u001b[0;36mNeuralForecast.fit\u001b[1;34m(self, df, static_df, val_size, sort_df, use_init_models, verbose)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels_fitted \u001b[39m=\u001b[39m [deepcopy(model) \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels]\n\u001b[0;32m    255\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels_fitted:\n\u001b[1;32m--> 256\u001b[0m     model\u001b[39m.\u001b[39mfit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, val_size\u001b[39m=\u001b[39mval_size)\n\u001b[0;32m    258\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fitted \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\code\\project\\neuralforecast\\neuralforecast\\common\\_base_windows.py:677\u001b[0m, in \u001b[0;36mBaseWindows.fit\u001b[1;34m(self, dataset, val_size, test_size, random_seed)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcheck_val_every_n_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    676\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer_kwargs)\n\u001b[1;32m--> 677\u001b[0m trainer\u001b[39m.\u001b[39mfit(\u001b[39mself\u001b[39m, datamodule\u001b[39m=\u001b[39mdatamodule)\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:531\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    529\u001b[0m model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 531\u001b[0m call\u001b[39m.\u001b[39m_call_and_handle_interrupt(\n\u001b[0;32m    532\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    533\u001b[0m )\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     44\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     45\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:570\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[0;32m    561\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[0;32m    562\u001b[0m )\n\u001b[0;32m    564\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    565\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    566\u001b[0m     ckpt_path,\n\u001b[0;32m    567\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    568\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m )\n\u001b[1;32m--> 570\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(model, ckpt_path\u001b[39m=\u001b[39mckpt_path)\n\u001b[0;32m    572\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    573\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:975\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    972\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_stage()\n\u001b[0;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    980\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1016\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m   1015\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1016\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1017\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1018\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1045\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1042\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1044\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1045\u001b[0m val_loop\u001b[39m.\u001b[39mrun()\n\u001b[0;32m   1047\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1049\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[0;32m    176\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m     previous_dataloader_idx \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m    114\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[0;32m    116\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:375\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[0;32m    374\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 375\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39mstep_kwargs\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m    377\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[0;32m    379\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_test_batch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mon_validation_batch_end\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:287\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 287\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    290\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32md:\\app\\anaconda\\envs\\deeplearning\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:379\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m    378\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 379\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mvalidation_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\code\\project\\neuralforecast\\neuralforecast\\common\\_base_windows.py:497\u001b[0m, in \u001b[0;36mBaseWindows.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m    496\u001b[0m \u001b[39m# TODO: Hack to compute number of windows\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m windows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_windows(batch, step\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    498\u001b[0m n_windows \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(windows[\u001b[39m\"\u001b[39m\u001b[39mtemporal\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    500\u001b[0m \u001b[39m# Number of windows in batch\u001b[39;00m\n",
      "File \u001b[1;32md:\\code\\project\\neuralforecast\\neuralforecast\\common\\_base_windows.py:279\u001b[0m, in \u001b[0;36mBaseWindows._create_windows\u001b[1;34m(self, batch, step, w_idxs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    273\u001b[0m     (step \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    274\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m    275\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfutr_exog_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m    276\u001b[0m ):\n\u001b[0;32m    277\u001b[0m     temporal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadder(temporal)\n\u001b[1;32m--> 279\u001b[0m windows \u001b[39m=\u001b[39m temporal\u001b[39m.\u001b[39munfold(\n\u001b[0;32m    280\u001b[0m     dimension\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, size\u001b[39m=\u001b[39mwindow_size, step\u001b[39m=\u001b[39mpredict_step_size\n\u001b[0;32m    281\u001b[0m )\n\u001b[0;32m    283\u001b[0m \u001b[39m# [batch, channels, windows, window_size] 0, 1, 2, 3\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[39m# -> [batch * windows, window_size, channels] 0, 2, 3, 1\u001b[39;00m\n\u001b[0;32m    285\u001b[0m windows_per_serie \u001b[39m=\u001b[39m windows\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: maximum size for tensor at dimension 2 is 132 but size is 812"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import MLP\n",
    "from neuralforecast.losses.pytorch import MQLoss, DistributionLoss\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "from neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic, augment_calendar_df\n",
    "\n",
    "AirPassengersPanel, calendar_cols = augment_calendar_df(df=AirPassengersPanel, freq='M')\n",
    "\n",
    "Y_train_df = AirPassengersPanel[AirPassengersPanel.ds<AirPassengersPanel['ds'].values[-12]] # 132 train\n",
    "Y_test_df = AirPassengersPanel[AirPassengersPanel.ds>=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n",
    "\n",
    "model = PatchTST(h=12,\n",
    "                 input_size=12*10,\n",
    "                 patch_len=24,\n",
    "                 stride=24,\n",
    "                 revin=False,\n",
    "                 hidden_size=16,\n",
    "                 n_heads=4,\n",
    "                 scaler_type='robust',\n",
    "                #  loss=DistributionLoss(distribution='StudentT', level=[80, 90]),\n",
    "                 loss=MAE(),\n",
    "                 learning_rate=1e-3,\n",
    "                 max_steps=500,\n",
    "                 val_check_steps=50,\n",
    "                 early_stop_patience_steps=2)\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models=[model],\n",
    "    freq='M'\n",
    ")\n",
    "nf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\n",
    "forecasts = nf.predict(futr_df=Y_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "Y_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\n",
    "plot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\n",
    "plot_df = pd.concat([Y_train_df, plot_df])\n",
    "\n",
    "if model.loss.is_distribution_output:\n",
    "    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n",
    "    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "    plt.plot(plot_df['ds'], plot_df['PatchTST-median'], c='blue', label='median')\n",
    "    plt.fill_between(x=plot_df['ds'][-12:], \n",
    "                    y1=plot_df['PatchTST-lo-90'][-12:].values, \n",
    "                    y2=plot_df['PatchTST-hi-90'][-12:].values,\n",
    "                    alpha=0.4, label='level 90')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.plot()\n",
    "else:\n",
    "    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n",
    "    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "    plt.plot(plot_df['ds'], plot_df['PatchTST'], c='blue', label='Forecast')\n",
    "    plt.legend()\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
