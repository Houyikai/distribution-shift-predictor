{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models.mixmodel_rescale_deco import MIXModel\n",
    "from neuralforecast.losses.pytorch import MAE, MSE\n",
    "from neuralforecast.models import Autoformer, FEDformer, Informer, PatchTST, NBEATS, NHITS, MLP\n",
    "from datasetsforecast.long_horizon2 import LongHorizon2, LongHorizon2Info\n",
    "\n",
    "input_size = 96\n",
    "horizon = 192\n",
    "dataset = \"ETTh1\"\n",
    "epochs = 300\n",
    "loss=MAE()\n",
    "n_heads = 4\n",
    "hidden_size = 64\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# read dataï¼š\n",
    "Y_df = LongHorizon2.load(directory=\"./data/\", group=dataset)\n",
    "Y_df[\"ds\"] = pd.to_datetime(Y_df[\"ds\"])\n",
    "n_time = LongHorizon2Info[dataset].n_time\n",
    "freq = LongHorizon2Info[dataset].freq\n",
    "val_size = LongHorizon2Info[dataset].val_size\n",
    "test_size = LongHorizon2Info[dataset].test_size\n",
    "Y_df.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "informer = Informer(\n",
    "  h=horizon,\n",
    "  input_size=input_size,\n",
    "  loss = loss,\n",
    "  max_steps = epochs,\n",
    "  n_head = n_heads,\n",
    "  hidden_size = hidden_size,\n",
    "  batch_size = batch_size,\n",
    "  learning_rate = learning_rate,\n",
    ")\n",
    "\n",
    "autoformer = Autoformer(\n",
    "  h=horizon,\n",
    "  input_size=input_size,\n",
    "  loss = loss,\n",
    "  max_steps = epochs,\n",
    "  n_head = n_heads,\n",
    "  hidden_size = hidden_size,\n",
    "  batch_size = batch_size,\n",
    "  learning_rate = learning_rate,\n",
    ")\n",
    "\n",
    "fedformer = FEDformer(\n",
    "  h=horizon,\n",
    "  input_size=input_size,\n",
    "  loss = loss,\n",
    "  max_steps = epochs,\n",
    "  n_head = 8,\n",
    "  hidden_size = hidden_size,\n",
    "  batch_size = batch_size,\n",
    "  learning_rate = learning_rate,\n",
    ")\n",
    "\n",
    "drnn = MLP(\n",
    "  h=horizon,\n",
    "  input_size=input_size,\n",
    "  loss = loss,\n",
    "  max_steps = epochs,\n",
    "  batch_size = batch_size,\n",
    "  learning_rate = learning_rate,\n",
    ")\n",
    "\n",
    "patchtst = PatchTST(\n",
    "  h=horizon,\n",
    "  input_size=input_size,\n",
    "  loss = loss,\n",
    "  max_steps = epochs,\n",
    "  n_heads = n_heads,\n",
    "  hidden_size = hidden_size,\n",
    "  batch_size = batch_size,\n",
    "  learning_rate = learning_rate,\n",
    ")\n",
    "\n",
    "nbeats = NBEATS(\n",
    "  h=horizon,\n",
    "  input_size=512,\n",
    "  loss = loss,\n",
    "  max_steps = epochs,\n",
    ")\n",
    "\n",
    "nhits = NHITS(\n",
    "  h=horizon,\n",
    "  input_size=512,\n",
    "  loss = loss,\n",
    "  max_steps = epochs,\n",
    ")\n",
    "\n",
    "models = [drnn, informer, autoformer, fedformer, patchtst, nbeats, nhits]\n",
    "\n",
    "for model in models:\n",
    "  # fit & test model\n",
    "  nf = NeuralForecast(models=[model], freq=freq)\n",
    "  Y_hat_df = nf.cross_validation(df=Y_df, val_size=val_size, test_size=test_size,step_size=1, n_windows=None)\n",
    "  Y_hat_df.to_csv(f'./data/{dataset}_{horizon}_{nf.models[0]}.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hencoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
